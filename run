#!/usr/bin/env python
import sys
sys.dont_write_bytecode = True

import os
import argparse
import secrets
import tempfile


if __name__ != "__main__":
    raise ImportError("This script cannot be imported as a module")

parser = argparse.ArgumentParser(description='A one-liner for GSAI slurm sbatch scripts')

env_group = parser.add_mutually_exclusive_group()
env_group.add_argument('--venv', action='store_true', help='Use the default virtual environment')
env_group.add_argument('--conda', type=str, help='Use a Conda environment with the given name')
env_group.add_argument('--docker', type=str, help='Use a Docker image with the given name')
env_group.add_argument('--singularity', type=str, help='Use a Singularity image with the given file name')

parser.add_argument('--jobname', type=str, required=True, help='Name of the job')
parser.add_argument('--partition', type=str, required=True, help='Slurm partition to use')
parser.add_argument('--n_gpus', type=int, required=True, help='Number of GPUs to request')
parser.add_argument('--n_cpus', type=int, required=True, help='Number of CPUs to request')
parser.add_argument('--time', type=str, required=True, help='Time limit for the job (e.g., 01:00:00 for 1 hour)')

parser.add_argument('--precopy', nargs=2, action='append', metavar=('SRC', 'DST'), required=False, help='Specify a source and destination pair for file pre-copying')
parser.add_argument('--postcopy', nargs=2, action='append', metavar=('SRC', 'DST'), required=False, help='Specify a source and destination pair for file post-copying')

parser.add_argument('command', nargs='+', help='The command to execute')

args = parser.parse_args()

status_code = """
#!/bin/bash

cd $SLURM_SUBMIT_DIR
echo "SLURM_JOB_NAME=$SLURM_JOB_NAME"
echo "SLURM_JOB_ID=$SLURM_JOB_ID"
echo "SLURM_SUBMIT_DIR=$SLURM_SUBMIT_DIR"

echo "HOSTNAME: $(hostname)"
echo "DATE: $(date)"

echo "%%%%%%%%%%%% GPU INFO %%%%%%%%%%%%"
echo "CUDA_HOME=$CUDA_HOME"
echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
echo "CUDA_VERSION=$CUDA_VERSION"

nvidia-smi
nvidia-smi -L
"""

sbatch_script = tempfile.NamedTemporaryFile(mode='w', delete=False)
print('Creating sbatch script at:', sbatch_script.name)

if args.venv:
    run_prefix = 'source .venv/bin/activate; which python; '
elif args.conda:
    run_prefix = f'conda activate {args.conda}; which python; '
elif args.docker:
    _docker_setup = 'export UUIDLIST=$(nvidia-smi -L | cut -d \'(\' -f 2 | awk \'{print$2}\' | tr -d ")" | paste -s -d, -); export GPULIST=\"device=${UUIDLIST}\"; export CPULIST=$(grep "Cpus_allowed_list" /proc/self/status | awk \'{print $2}\'); '
    _docker_rand = secrets.token_urlsafe(20)
    run_prefix = f'docker run --rm --pull always --init --gpus $GPULIST --cpuset-cpus $CPULIST -e WANDB_API_KEY=$WANDB_API_KEY --volume $(pwd):/workspace --name $(whoami)_{_docker_rand} {args.docker} '
    run_prefix = _docker_setup + run_prefix
elif args.singularity:
    _singularity_setup = 'ml singularity; '
    run_prefix = f'singularity exec --nv --env WANDB_API_KEY=$WANDB_API_KEY --bind $(pwd):/workspace {args.singularity} '
    run_prefix = _singularity_setup + run_prefix
else:
    run_prefix = ''

pre_copy = []
post_copy = []
cleanup = []

for precp_src, precp_dst in args.precopy:
    pre_copy.append(f'cp -r {precp_src} {precp_dst}')
    cleanup.append(f'rm -drf {precp_dst}')

for postcp_src, postcp_dst in args.postcopy:
    post_copy.append(f'cp -r {postcp_src} {postcp_dst}')
    cleanup.append(f'rm -drf {postcp_src}')

command = ' '.join(args.command)
sbatch_script.write(status_code + '\n\n')
sbatch_script.write('\n'.join(pre_copy) + '\n\n')
sbatch_script.write(run_prefix + command + '\n\n')
sbatch_script.write('\n'.join(post_copy) + '\n\n')
sbatch_script.write('\n'.join(cleanup) + '\n\n')
sbatch_script.close()

qos = ''
if 'A100' in args.partition and 'PCI' not in args.partition:
    qos = '--qos=hpgpu'

stdout_path = f'$HOME/slurm_log/out/$job_name.{args.jobname}.out'
stderr_path = f'$HOME/slurm_log/err/$job_name.{args.jobname}.err'
sbatch_command = f'sbatch --job-name={args.jobname} --out {stdout_path} --err {stderr_path} --partition={args.partition} -N 1 -n 1 --gres=gpu:{args.n_gpus} {qos} --cpus-per-task={args.n_cpus} --time={args.time} {sbatch_script.name}'

os.system(sbatch_command)
