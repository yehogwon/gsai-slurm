#!/usr/bin/env python
import sys
sys.dont_write_bytecode = True

import os
from os.path import join as pjoin

import subprocess
import tempfile
import atexit

import argparse
import secrets


SLURM_LOCAL_DATA = '/local-data/user-data/$USER/$SLURM_JOB_ID'
CLEANUP_GRACE_PERIOD = 120  # seconds


def print_blue(*args, **kwargs):
    print('\033[1;34m', end='')
    print(*args, **kwargs)
    print('\033[0m', end='')


def print_red(*args, **kwargs):
    print('\033[1;31m', end='')
    print(*args, **kwargs)
    print('\033[0m', end='')


def print_green(*args, **kwargs):
    print('\033[1;32m', end='')
    print(*args, **kwargs)
    print('\033[0m', end='')


def raise_die(msg: str, code: int=1):
    print_red(msg)
    sys.exit(code)


def randomize(length: int=8) -> str:
    return secrets.token_urlsafe(length)


def join_newline(lst, num_newlines=1):
    sep = '\n' * num_newlines if num_newlines > 0 else ' '
    return sep.join(lst)


def _find_conda_init() -> str:
    CONDA_LOCATIONS = (
        os.path.expanduser('~/anaconda3'),
        os.path.expanduser('~/miniconda3'),
        '/opt/anaconda3',
        '/opt/miniconda3',
        '/opt/ohpc/pub/apps/anaconda3',
        '/opt/ohpc/pub/apps/miniconda3',
    )

    for loc in CONDA_LOCATIONS:
        if os.path.exists(loc):
            return pjoin(loc, 'etc/profile.d/conda.sh')
    return os.path.expanduser('~/.bashrc')


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description='A one-liner for GSAI slurm sbatch scripts')

    env_group = parser.add_mutually_exclusive_group()
    env_group.add_argument('--venv', action='store_true', help='Use the default virtual environment')
    env_group.add_argument('--conda', type=str, help='Use a Conda environment with the given name')
    env_group.add_argument('--docker', type=str, help='Use a Docker image with the given name')
    env_group.add_argument('--singularity', type=str, help='Use a Singularity image with the given file name')

    parser.add_argument('--jobname', type=str, required=True, help='Name of the job')
    parser.add_argument('--stdout', type=str, default='$HOME/slurm_log/out', help='Directory for standard output logs')
    parser.add_argument('--stderr', type=str, default='$HOME/slurm_log/err', help='Directory for standard error logs')
    parser.add_argument('--partition', type=str, required=True, help='Slurm partition to use')
    parser.add_argument('--nodelist', type=str, default=None, help='Specific node list to use (optional)')
    parser.add_argument('--n_gpus', type=int, required=True, help='Number of GPUs to request')
    parser.add_argument('--n_cpus', type=int, required=True, help='Number of CPUs to request')
    parser.add_argument('--time', type=str, required=True, help='Time limit for the job (e.g., 01:00:00 for 1 hour)')
    parser.add_argument('--mem', type=str, default=0, help='Memory to request (0 for default; e.g., 16G)')

    parser.add_argument('--precopy', nargs=2, action='append', metavar=('NAME', 'SRC'), required=False, default=[], help='Specify a source and destination pair for file pre-copying')
    parser.add_argument('--postcopy', nargs=2, action='append', metavar=('NAME', 'DST'), required=False, default=[], help='Specify a source and destination pair for file post-copying')

    parser.add_argument('command', nargs=argparse.REMAINDER, help='The command to execute')

    args = parser.parse_args()
    return args


def copy_cleanups(args: argparse.Namespace) -> tuple[str, str, str, dict[str, str]]:
    preproc = []
    postproc = []
    mappings = {}

    _names = [n for n, _ in (args.precopy + args.postcopy)]
    if len(_names) != len(set(_names)):
        raise_die('Error: Duplicate names found in precopy/postcopy arguments')

    precp_prefix = pjoin(SLURM_LOCAL_DATA, 'PRE')
    postcp_prefix = pjoin(SLURM_LOCAL_DATA, 'POST')

    preproc.append(f'mkdir -p "{precp_prefix}"')
    preproc.append(f'mkdir -p "{postcp_prefix}"')

    for precp_name, precp_src in (args.precopy):
        precp_src = precp_src.rstrip('/')

        if not os.path.exists(precp_src):
            raise_die(f'Precopy source path does not exist: {precp_src}')

        src_parent, src_name = os.path.split(precp_src)
        if not src_parent:
            src_parent = '.'
        path = pjoin(precp_prefix, randomize())
        mappings[precp_name] = pjoin(path, src_name)

        preproc.append(f'mkdir -p "{path}"')
        preproc.append(f'tar -cf - -C "{src_parent}" "{src_name}" | tar -xf - -C "{path}"')

    for postcp_name, postcp_dst in (args.postcopy):
        postcp_dst = postcp_dst.rstrip('/')

        path = pjoin(postcp_prefix, randomize())
        mappings[postcp_name] = path

        preproc.append(f'mkdir -p "{path}"')
        postproc.append(f'mkdir -p "{postcp_dst}"')
        postproc.append(f'tar -cf - -C "{path}" . | tar -xf - -C "{postcp_dst}"')

    # EXIT trap for cleanup - runs on any exit (normal, error, or after signal)
    trap_cleanup = join_newline([
        'cleanup__() {',
        '    echo " *** Running cleanup... *** "',
        f'    rm -drf "{SLURM_LOCAL_DATA}"'
        '    echo " *** Cleanup complete *** "',
        '}',
        'trap cleanup__ EXIT',
        'trap \'echo " *** Signal received, will postcopy after command exits... *** "\' SIGTERM SIGINT',
    ])

    return (
        join_newline(preproc),
        join_newline(postproc),
        trap_cleanup,
        mappings
    )


def write_sbatch_script(args: argparse.Namespace) -> str:
    status_code = join_newline([
        '#!/bin/bash',
        'cd $SLURM_SUBMIT_DIR',
        'echo "SLURM_JOB_NAME=$SLURM_JOB_NAME"',
        'echo "SLURM_JOB_ID=$SLURM_JOB_ID"',
        'echo "SLURM_SUBMIT_DIR=$SLURM_SUBMIT_DIR"',
        'echo "HOSTNAME: $(hostname)"',
        'echo "DATE: $(date)"',
        'echo "%%%%%%%%%%%% GPU INFO %%%%%%%%%%%%"',
        'echo "CUDA_HOME=$CUDA_HOME"',
        'echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"',
        'echo "CUDA_VERSION=$CUDA_VERSION"',
        'nvidia-smi',
        'nvidia-smi -L',
    ])

    sbatch_script = tempfile.NamedTemporaryFile(mode='w', delete=False)
    script_path = sbatch_script.name
    atexit.register(os.remove, script_path)

    if args.venv:
        run_prefix = 'source .venv/bin/activate; which python; '
    elif args.conda:
        run_prefix = join_newline([
            'source ' + _find_conda_init(),
            f'conda activate {args.conda}; which python; '
        ])
    elif args.docker:
        # _docker_setup = '  '
        _docker_setup = join_newline([
            'export UUIDLIST=$(nvidia-smi -L | cut -d \'(\' -f 2 | awk \'{print$2}\' | tr -d ")" | paste -s -d, -)',
            'export GPULIST="device=${UUIDLIST}"',
            'export CPULIST=$(grep "Cpus_allowed_list" /proc/self/status | awk \'{print $2}\');'
        ])
        _docker_rand = randomize()
        run_prefix = f'docker run --rm --pull always --init --gpus $GPULIST --cpuset-cpus $CPULIST -e WANDB_API_KEY=$WANDB_API_KEY --volume $(pwd):/workspace --name $(whoami)_{_docker_rand} {args.docker} '
        run_prefix = join_newline([_docker_setup, run_prefix])
    elif args.singularity:
        run_prefix = f'singularity exec --nv --env WANDB_API_KEY=$WANDB_API_KEY --bind $(pwd):/workspace {args.singularity} '
    else:
        run_prefix = ''

    precopy, postcopy, cleanup, copy_lookup = copy_cleanups(args)
    parsed_command = join_newline(args.command, num_newlines=0)
    for name, path in copy_lookup.items():
        if ' ' in path:
            raise_die(f'Error: Path "{path}" for name "{name}" contains spaces, which is not expected.')
        parsed_command = parsed_command.replace('{{' + name + '}}', f'{path}')
    exec_cmd = run_prefix + parsed_command

    script_contents = []
    script_contents.append(status_code)
    script_contents.append(cleanup)  # trap setup
    script_contents.append('echo " *** Precopying *** "')
    script_contents.append(precopy)
    script_contents.append('echo " *** Executing command *** "')
    script_contents.append(exec_cmd)
    script_contents.append('CMD_EXIT_CODE=$?')  # capture exit code
    script_contents.append('echo " *** Command exited with code $CMD_EXIT_CODE *** "')
    script_contents.append('echo " *** Postcopying *** "')
    script_contents.append(postcopy)
    script_contents.append('exit $CMD_EXIT_CODE')  # preserve original exit code

    script_contents = join_newline(script_contents, num_newlines=2)
    sbatch_script.write(script_contents)
    sbatch_script.close()

    print_green('Wrote the following sbatch script:')
    print(script_contents, end='\n\n')
    print_green('to:', end=' ')
    print(script_path, end='\n\n')

    return script_path


def execute_sbatch(script_path: str, args: argparse.Namespace):
    sbatch_args = []

    # required args
    sbatch_args.append(('--job-name', args.jobname))
    sbatch_args.append(('--out', pjoin(args.stdout, '%x.%j.out')))  # jobname.jobid.out
    sbatch_args.append(('--err', pjoin(args.stderr, '%x.%j.err')))  # jobname.jobid.err
    sbatch_args.append(('--partition', args.partition))
    sbatch_args.append(('--nodes', '1'))  # TODO: support multi-node distributed jobs
    sbatch_args.append(('--ntasks', '1'))
    sbatch_args.append(('--gres', f'gpu:{args.n_gpus}'))
    sbatch_args.append(('--cpus-per-task', args.n_cpus))
    sbatch_args.append(('--time', args.time))
    sbatch_args.append(('--signal', f'SIGTERM@{CLEANUP_GRACE_PERIOD}'))

    # optional args
    if args.nodelist:
        sbatch_args.append(('--nodelist', args.nodelist))
    if args.mem != 0:
        sbatch_args.append(('--mem', args.mem))

    if args.n_gpus == 0:
        sbatch_args.append(('--qos', 'nogpu'))
    elif 'A100' in args.partition and 'PCI' not in args.partition:
        sbatch_args.append(('--qos', 'hpgpu'))

    sbatch_args = join_newline([f'{k} {v}' for k, v in sbatch_args], num_newlines=0)
    sbatch_command = f'sbatch {sbatch_args} {script_path}'

    print_green('Running the following sbatch command:')
    print(sbatch_command, end='\n\n')

    subprocess.run(sbatch_command, shell=True)


if __name__ == '__main__':
    args = parse_args()
    path = write_sbatch_script(args)
    execute_sbatch(path, args)
else:
    raise_die("This script cannot be imported as a module")
